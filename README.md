# HNet-GPT
HNet-GPT: Structure-Aware Code Generation via Hierarchical Encoding and Transformer Decoding, a novel Hybrid architecture


# HNet-GPT: Structure-Aware Code Generation via Hierarchical Encoding and Transformer Decoding

**Preliminary Research** - Seeking community validation and collaboration

## Initial Results
- **40.6%** improvement over Pure GPT-2
- **39.5%** improvement over Pure HNet
- Comprehensive evaluation on MBPP dataset

## Call for Collaboration
I am  open-sourcing everything to:
- Enable reproducibility
- Gather community feedback
- Validate results across different setups
- Explore further improvements

## Preliminary Findings
[Your three-way comparison results]

## Next Steps
- [ ] Scale to larger models --> more recent GPT
- [ ] Test on more datasets --> train on C/C++
- [ ] Optimize architecture
- [ ] Community feedback integration
